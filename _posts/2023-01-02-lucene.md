---
title: Lucene一文吃透
author: Lynn
date: 2023-01-02
category: search
layout: post
---

## 1 是什么？
一句话描述：搜索引擎，以全文检索、倒排查询、可扩展性、高性能为卖点。

## 2 核心概念

#### 索引库index
类似数据库的表的概念，一份已经被构建好的库。

#### 文档doc
一个doc就是一条数据。
field是数据的字段。

#### 段segment
一个index由多个segment组成，一个segment内包含多个doc。为什么分段？避免多个请求改动同一个文件，同时也可以增加建库和查询的效率。
segment是存储层的概念，在用户api层不涉及。设计思想与LSM类似但又有些不同。
Lucene中的数据写入会先写内存的一个Buffer（类似LSM的MemTable，但是不可读），当Buffer内数据到一定量后会被flush成一个Segment。
每个Segment有自己独立的索引，可独立被查询，但数据永远不能被更改。这种模式避免了随机写，数据写入都是Batch和Append，能达到很高的吞吐量。
文档不可被修改，但可被删除，删除的方式也不是在文件内部原地更改，而是会由另外一个文件保存需要被删除的文档的DocID。
Lucene中对数据索引的构建会在Segment flush时，而非实时构建，目的是为了构建最高效索引。这也就是为什么Lucene被称为提供近实时而非实时查询的原因。

#### term
内容切词的最小单位称为term, 比如"今天天气真好”, 切为"今天" "天气" "真好”三个term。
term事实上就是doc的内容单元。

#### 倒排索引查询reverse index
根据数据id查询数据属性，叫做正排查询。反过来，根据数据的一个属性查询数据id，称之为倒排查询。

#### 相关性打分tf-idf
term-frequence，某个词在文档中出现的次数。
document frequency，某个词在多少个文档中出现。
simlarity = TF1*IDF1 + TF2*IDF2 + ... + TFn*IDFn

#### 准召
准确率=获取的正确的文档的个数 / 获取的全部文档的个数
召回率=获取的正确的文档的个数 / 库中正确文档的个数 

#### 分词analyzer
将输入的文档或者输入的查询串解析成tokens，在索引构建器或者查询器中被处理成term，进而进行索引或者查询。

#### 文件
段内的正排文件：tvx、tvd、tvf；
倒排信息：tis、tii、frq文件；

#### Term Dict

#### Term Index


## 3 核心流程

### 在线查询（读）
简单版：
1. 根据每个term，通过TermIndex查到是否存在以及位置
2. 根据term和位置，通过TermDict查到posting
3. 多个posting做拉链归并
详细版：
1. 通过 Term Index 数据（.tip文件）中的 StartFP 获取指定字段的 FST
2. 通过 FST 找到指定 Term 在 Term Dictionary（.tim 文件）可能存在的 Block
3. 将对应 Block 加载内存，遍历 Block 中的 Entry，通过后缀（Suffix）判断是否存在指定 Term
4. 存在则通过 Entry 的 TermStat 数据中各个文件的 FP 获取 Posting 数据
5. 按需求对posting做处理

![查询流程](/assets/lucene_search.jpeg)

### 索引构建（写）
1. Analyzer
2. IndexWriter


## 4 优化点
#### FST vs Skip vs Hash


